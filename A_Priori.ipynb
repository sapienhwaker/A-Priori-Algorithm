{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "A-Priori.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sapienhwaker/A-Priori-Algorithm/blob/main/A_Priori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTadYLtNjJ35"
      },
      "source": [
        "## Project-1: Distributed Association Rule Mining\n",
        "### Prasad Hajare (A20232707)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLB5jvinjJ4A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54ddcd58-b6ad-4c05-f083-b76480a95ac8"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7tyjFqFjg_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60c5c8c0-a00d-4982-ff28-cd8a432554e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqIDzmcV_isd"
      },
      "source": [
        "import re\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext(\"local\", \"Distributed Association Rule Mining\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_8hpHna_qL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "311a2447-b6bc-4da8-b95b-531d71f9d9fb"
      },
      "source": [
        "file = \"/content/drive/My Drive/BIGDATA Fall2020/browsing.txt\"\n",
        "\n",
        "# reading input file\n",
        "fileRDD = sc.textFile(file)\n",
        "\n",
        "# total Baskets count\n",
        "print('Total number of baskets = ', fileRDD.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of baskets =  31101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_og__tiWJAaC"
      },
      "source": [
        "basketsRDD = fileRDD.map(lambda line: re.split(r'\\W+', line.strip()))\n",
        "#for i in range(0,10):\n",
        "  #print(basketsRDD.collect()[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxOKIa_wouvP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ed9f0f0-b1c3-4022-c611-ae0567c4f712"
      },
      "source": [
        "# function to give index to every basket\n",
        "def indexing(record):\n",
        "  l = []\n",
        "  for item in record[0]:\n",
        "    l.append((item,record[1]))\n",
        "  return l\n",
        "\n",
        "#every basket will be numbered from 0, 1, 2, ....\n",
        "#then a table will be created for every item.\n",
        "#Where item will be the key and list of baskets in which the item is present will be the value\n",
        "#later this table will be used to find most frequent item sets for different k values\n",
        "\n",
        "indexedBasketsRDD = basketsRDD.zipWithIndex().map(indexing)\n",
        "tempMapRDD = indexedBasketsRDD.flatMap(lambda x: x).map(lambda x: (x[0],[x[1]]))\n",
        "mapRDD = tempMapRDD.reduceByKey(lambda list1,list2: list1 + list2).map(lambda x: (x[0], frozenset(x[1])))\n",
        "\n",
        "#for i in range(0,10):\n",
        "  #print(mapRDD.collect()[i])\n",
        "\n",
        "print('Total Records = ', mapRDD.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Records =  12592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m5e-2kMqiWZ"
      },
      "source": [
        "dictionaryRDD = mapRDD.collectAsMap()\n",
        "broadDictionaryRDD = sc.broadcast(dictionaryRDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQpm-eXpMSbD"
      },
      "source": [
        "***Finding frequent itemsets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hJZ4grDAp-f"
      },
      "source": [
        "support = 85\n",
        "k = 1\n",
        "\n",
        "wordsRDD = fileRDD.flatMap(lambda line: re.split(r'\\W+', line.strip()))\n",
        "singleFrequentItemsRDD = wordsRDD.map(lambda x: (x,1)).reduceByKey(lambda a,b: a+b).filter(lambda x: x[1] >= support)\n",
        "\n",
        "#qualifiers is a list which will collect all the qualified frequent item sets which has k=1,2,3,4 and support >= 85\n",
        "qualifiers = []\n",
        "qualifiers.append(singleFrequentItemsRDD.collect())\n",
        "#for i in range(0,10):\n",
        "  #print(singleFrequentItemsRDD.collect()[i])\n",
        "#print(f'Unique items with support >= 85 : ', itemsRDD.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN7RVZzPMXOD"
      },
      "source": [
        "***Frequent Itemsets for k = 2,3,4***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUiekYUIdE9I"
      },
      "source": [
        "# function for getting eligible item sets depending on the given support value\n",
        "support = 85\n",
        "def eligibleItems(x):\n",
        "  first_item = True\n",
        "  for item in x:\n",
        "    if first_item:\n",
        "      itemset = broadDictionaryRDD.value[item]\n",
        "      first_item = False\n",
        "    else:\n",
        "      itemset = itemset.intersection(broadDictionaryRDD.value[item])\n",
        "  \n",
        "  if len(itemset) >= support:\n",
        "    return x,len(itemset)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGe6WkvNvwFK"
      },
      "source": [
        "# function for getting frequent itemsets\n",
        "\n",
        "def frequent_itemset(prev, frequent_items, k, qualifiers):\n",
        "  if k == 2:\n",
        "    cartesianRDD = prev.cartesian(frequent_items).map(lambda x: frozenset(x))\n",
        "  else:\n",
        "    cartesianRDD = prev.cartesian(frequent_items).map(lambda x: frozenset(x[0]+tuple([x[1]])))\n",
        "    \n",
        "  eligibleRDD = cartesianRDD.filter(lambda x: len(x) == k).distinct().map(lambda x: tuple(x))\n",
        "  #print(f'Total candidate itemsets (k = {k}) : ', eligibleRDD.count())\n",
        "\n",
        "  mulitpleItemsRDD = eligibleRDD.map(eligibleItems).filter(lambda x: x)\n",
        "  \n",
        "  #if k == 2:\n",
        "    #twoFrequentItemsRDD = sc.parallelize(mulitpleItemsRDD.collect());\n",
        "  #if k == 3:\n",
        "    #threeFrequentItemsRDD = sc.parallelize(mulitpleItemsRDD.collect());\n",
        "  #if k == 4:\n",
        "    #fourFrequentItemsRDD = sc.parallelize(mulitpleItemsRDD.collect());\n",
        "  \n",
        "  qualifiers.append(mulitpleItemsRDD.collect())\n",
        "  #print(f'Total frequent itemsets (k = {k}) : ', mulitpleItemsRDD.count())\n",
        "\n",
        "  prev = mulitpleItemsRDD.map(lambda x: x[0])\n",
        "  prev.persist()\n",
        "\n",
        "  if k < 4:\n",
        "    frequent_itemset(prev, frequent_items, k+1, qualifiers)\n",
        "  else:\n",
        "    return\n",
        "\n",
        "singleFrequentItemsKeysRDD = singleFrequentItemsRDD.map(lambda x: x[0])\n",
        "singleFrequentItemsKeysRDD.persist()\n",
        "frequent_itemset(singleFrequentItemsKeysRDD, singleFrequentItemsKeysRDD, 2, qualifiers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7-EHEtf12mr"
      },
      "source": [
        "***Association rule implementation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-gRk_a51-Jq"
      },
      "source": [
        "import itertools as it\n",
        "c = 0.9\n",
        "\n",
        "#function to get the association\n",
        "#seperate: indicates how many parameters will be there on the left hand side of the association rule\n",
        "#x is single record and map is a dictionary\n",
        "\n",
        "def get_association(x,map,seperate,k):\n",
        "  li = []\n",
        "  for item in it.combinations(x[0],seperate):\n",
        "    if k == 2:\n",
        "      confidence = x[1]/map[frozenset({item[0]})]\n",
        "    else:\n",
        "      confidence = x[1]/map[frozenset(item)]\n",
        "    if confidence >= c:\n",
        "      li.append((item, tuple(set(x[0])-set(item)), confidence*100))\n",
        "\n",
        "  if li:\n",
        "    return x,li\n",
        "  return\n",
        "\n",
        "# converting rdd to the dictionary/map\n",
        "singleFrequentItemsMapRDD = singleFrequentItemsRDD.map(lambda x: (frozenset({x[0]}),x[1])).collectAsMap()\n",
        "\n",
        "# qulifier list contains list at index 1 which is a twofrequent items rdd\n",
        "twoFrequentItemsRDD = sc.parallelize(qualifiers[1]).map(lambda x: (frozenset(x[0]),x[1]))\n",
        "twoFrequentItemsMapRDD = twoFrequentItemsRDD.collectAsMap()\n",
        "\n",
        "# qulifier list contains list at index 2 which is a threefrequent items rdd\n",
        "threeFrequentItemsRDD = sc.parallelize(qualifiers[2]).map(lambda x: (frozenset(x[0]),x[1]))\n",
        "threeFrequentItemsMapRDD = threeFrequentItemsRDD.collectAsMap()\n",
        "\n",
        "# qulifier list contains list at index 2 which is a fourfrequentitems rdd\n",
        "fourFrequentItemsRDD = sc.parallelize(qualifiers[3])\n",
        "\n",
        "twoItemsConfiedenceRDD = twoFrequentItemsRDD.map(lambda x : get_association(x,singleFrequentItemsMapRDD,1,2)).filter(lambda x: x)\n",
        "#print('Two items with confidence 90 or greater: ', twoItemsConfiedenceRDD.count())\n",
        "\n",
        "threeItemsConfiedenceRDD = threeFrequentItemsRDD.map(lambda x : get_association(x,twoFrequentItemsMapRDD,2,3)).filter(lambda x: x)\n",
        "#print('Three items with confidence 90 or greater: ', threeItemsConfiedenceRDD.count())\n",
        "\n",
        "fourItemsConfiedenceRDD = fourFrequentItemsRDD.map(lambda x : get_association(x,threeFrequentItemsMapRDD,3,4)).filter(lambda x: x)\n",
        "#print('Four items with confidence 90 or greater: ', fourItemsConfiedenceRDD.count())\n",
        "\n",
        "#storing output to the text file\n",
        "output = open(\"/content/drive/My Drive/BIGDATA Fall2020/association_rules.txt\", \"a\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UBWTqOuLBP4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a1d9ced-84be-46f3-b386-e8e0ab317e5f"
      },
      "source": [
        "output.write(\"Association rule for two items\\n\\n\")\n",
        "for val in twoItemsConfiedenceRDD.collect():\n",
        "  #print(val[1][0][0][0], '>>', val[1][0][1][0], ' {:.2f}'.format(val[1][0][2]), '%')\n",
        "  line = val[1][0][0][0] + ' >> ' + val[1][0][1][0] + ' {:.2f}'.format(val[1][0][2]) + '%\\n'\n",
        "  output.write(line)\n",
        "\n",
        "output.write(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPuf7WpPK72p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfacdfaf-2b87-4945-c3a7-fc4c6ee00a88"
      },
      "source": [
        "output.write(\"Association rule for three items\\n\\n\")\n",
        "for val in threeItemsConfiedenceRDD.collect():\n",
        "  line = str(val[1][0][0]) + ' >> ' + val[1][0][1][0] + ' {:.2f}'.format(val[1][0][2]) + '%\\n'\n",
        "  output.write(line)\n",
        "\n",
        "output.write(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBc64nr_4KI9"
      },
      "source": [
        "output.write(\"Association rule for four items\\n\\n\")\n",
        "for val in fourItemsConfiedenceRDD.collect():\n",
        "  line = str(val[1][0][0]) + ' >> ' + val[1][0][1][0] + ' {:.2f}'.format(val[1][0][2]) + '%\\n'\n",
        "  output.write(line)\n",
        "\n",
        "output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0tK_92CjJ6t"
      },
      "source": [
        "# Due Date: Sept. 17 at 11:59pm"
      ]
    }
  ]
}